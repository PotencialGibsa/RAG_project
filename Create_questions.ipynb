{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af34436e-6f1f-4970-8482-5a150137a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/importlib/__init__.py:126: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "/tmp/ipykernel_27797/2831752988.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=model_name,\n",
      "/home/dima/RAG_project/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/dima/RAG_project/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name,\n",
    "                                  model_kwargs=model_kwargs,\n",
    "                                  encode_kwargs=encode_kwargs)\n",
    "\n",
    "vector_store = Chroma('500100',embedding_function = embedding, persist_directory='DataBase/db_500_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d68d74-3783-469a-be18-5f07c73e713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.get()['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6b5db43-0376-48a6-a3b3-cf7fcb4639c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "ids_quest = random.sample(ids, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "269e3b82-09b7-4025-8503-44c51e5bf368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what in id\n",
    "some_id = vector_store.get(ids = [ids_quest[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de9b4cf0-4f5a-4773-8826-39b788d8323c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['355aae89-c1c1-45e2-9fd5-d20ce6c0e11c'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'page': 2, 'source': './Data/1792125902228222608.pdf'}],\n",
       " 'documents': ['ance InternationaL Evaluation Index (AGILE Index).  The index is utilized to delve into the sta-\\ntus of AI governance to date in 14 countries for the first batch of evaluation.  The aim is to depict the \\ncurrent state of AI governance in these countries through data scoring, assist them in identifying their \\ngovernance stage  and uncover ing governance issues, and ultimately offer insights for the enhance-\\nment of their AI governance systems.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e2e3e25-7421-4aff-a956-fb7222092a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "questions_df = pd.DataFrame(columns = ['id', 'source', 'page', 'context', 'question', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fbb2f95-ae31-43d3-a449-7a014dee6350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm functioning properly. What would you like to know or discuss?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import client\n",
    "client.client('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b447ddc-e8e6-4285-a5ff-9de6b9a40f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, id in enumerate(ids_quest):\n",
    "    id_doc = vector_store.get(ids = [id])\n",
    "    context = id_doc['documents'][0]\n",
    "    prompt = f\"\"\"\n",
    "    Придумай 1 вопрос и кратко ответь на него по приложенному тексту. Вопрос должен быть таким, что ответить на него можно только прочитав данный текст. К каждому вопросу напиши краткий ответ.\\\n",
    "    Приложенный текст: {context}\n",
    "    Формат вывода:\\\n",
    "    Вопрос: ...\\\n",
    "    Ответ: ...\\\n",
    "    \"\"\"\n",
    "\n",
    "    s = client.client(prompt)\n",
    "    qu = s[:s.find('\\n')].replace('Вопрос: ', '')\n",
    "    an = s[s.find('\\n'):].replace('\\nОтвет: ', '')\n",
    "    questions_df.loc[i] = [id, id_doc['metadatas'][0]['source'], id_doc['metadatas'][0]['page'], context, qu, an]\n",
    "    #print(client.client(prompt))\n",
    "    #print('Контекст:' , context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5e3e971-0fce-44a3-90ea-e8b6253c745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "for i in range(100):\n",
    "    start = 100 * i\n",
    "    stop = 100 * (i+1)\n",
    "    name = 'quest_data/quest_answer_context_' + str(i) + '.csv'\n",
    "    new_df = questions_df[start :stop]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f99b5087-0c91-4fc3-b6cf-ef19a4991836",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    questions_df.to_csv('quest_data/quest_answer_context_full' + '.csv')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcd17f4b-9dd6-4eb7-9f7f-a3ebce8f369d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d76d192c-2cc8-4a53-943a-cfec602f3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df[100:200].to_csv('1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429ee8b-a011-4089-9701-9d27f8b28a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_project",
   "language": "python",
   "name": "rag_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
